# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/124kQPgwQZJwd_Gs4ZEjm0QYuCG-EA5oU
"""

# Import Libraries
from google.colab import files
# To allow access to read google drive
from google.colab import drive
drive.mount('/content/drive')

from google.colab import drive
drive.mount('/content/drive')
import pandas as pd
# Reading CSV file

path="/content/drive/MyDrive/ML/Coating_Data_Set .csv"
# Using CSV instruction to read a txt file
# Reading Excel file
df_xls = pd.read_excel("/content/drive/MyDrive/ML/Coating_Data_Set.xlsx")

import numpy as np

df_array=np.array(df_xls)

# Converting Input Data
X_unnormalized =  df_array[:,0:3]
print(X_unnormalized.shape)

# Converting Y from MATLAB format to NUMPY format and rename it to Y_targets
Y_targets =  df_array[:,3] # Select the target Y and pass it onto the variable called Y_targets

print(Y_targets.shape)

from sklearn.model_selection import train_test_split # split the data into training and testing
from sklearn.preprocessing import StandardScaler  # Normalising the data
import matplotlib.pyplot as plt # for plotting results
from sklearn.preprocessing import MinMaxScaler # Normalizing data in the interval [0-1]

#  ---------     Using Normal distribution
normalise_to_Gaussian = StandardScaler()
X_normalised = normalise_to_Gaussian.fit_transform(X_unnormalized)
# np.amin(X_normalised[:,0])
np.amax(X_normalised)

# Normalizing the data to the Interval [0-1]
#  ---------     Normalise between [0-1]
# scaler = MinMaxScaler()
# scaler.fit(X_unnormalized)
# X_normalised = scaler.transform(X_unnormalized)

x_train, x_test, y_train, y_test = train_test_split(X_normalised, Y_targets, test_size=0.2,random_state = 42)
print(x_train.shape,y_train.shape, x_test.shape,y_test.shape)

# Importing modules that are required
from sklearn.datasets import load_boston
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score
from sklearn.linear_model import BayesianRidge, LinearRegression
from sklearn.metrics import mean_squared_error
from numpy import sqrt
   
# # Loading dataset
# dataset = load_boston()
# X, y = dataset.data, dataset.target
   
# # Splitting dataset into training and testing sets
# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 42)
   
# Creating and training model
model = BayesianRidge(tol=1e-5, fit_intercept=True, compute_score=True)
model.fit(x_train, y_train)
   
# Model making a prediction on test data
prediction = model.predict(x_test)
   
# Evaluation of r2 score of the model against the test set
print(f"r2 Score Of Test Set : {r2_score(y_test, prediction)}")

y_pred = model.predict(x_train)
plt.scatter(y_pred, y_train)
mse = mean_squared_error(y_train, y_pred)
print("MSE: %.2f" % mse)
print("RMSE: %.2f" % sqrt(mse))
plt.plot(y_train, y_train,'g-')
plt.title("Prediction of the Yield Strength for Training")
plt.xlabel("Output model")
plt.ylabel("Desired Prediction (Target)")
plt.show()